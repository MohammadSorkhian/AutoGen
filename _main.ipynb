{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a9c191a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, base64, asyncio, json, requests\n",
    "from openai import AzureOpenAI\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "# from autogen_ext.teams.magentic_one import MagenticOneGroupChat\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_agentchat.messages import UserMessage\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_core import CancellationToken\n",
    "from _clients._azureOpenAIChatCompletion_client import model_client\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField, \n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile\n",
    ")\n",
    "# from utility.llm_config import llm_config\n",
    "    \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve credentials from environment variables\n",
    "azure_openAI_api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openAI_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openAI_deployment_name = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "azure_openAI_api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "azure_search_endpoint = os.environ.get(\"AZURE_SEARCH_ENDPOINT\")\n",
    "azure_search_key = os.environ.get(\"AZURE_SEARCH_KEY\")\n",
    "azure_search_deployment_name = os.environ.get(\"AZURE_SEARCH_DEPLOYMENT_NAME\") \n",
    "\n",
    "vector_dimension = 1536  # Dimension for text-embedding-3-small\n",
    "datafile = \"./Data\"\n",
    "azure_search_index_name = \"rag-1756588180789\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2073db35",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     20\u001b[39m     assistant = AssistantAgent(\n\u001b[32m     21\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m         model_client=model_client,\n\u001b[32m     23\u001b[39m         tools=[search_tool, evaluator_tool],\n\u001b[32m     24\u001b[39m         system_message=\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m     )\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m Console(assistant.run_stream(task=\u001b[33m\"\u001b[39m\u001b[33mWrite a poem about the sea.\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# writer = AssistantAgent(\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m#     name=\"writer\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m#     system_message=\"Write well.\",\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     search_tool = \u001b[43mAgentTool\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msearchDocuments_tool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     evaluator_tool = AgentTool(agent=AISearchResultEvaluator_tool)\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# Create model client with parallel tool calls disabled for the main agent\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen_agentchat\\tools\\_agent.py:62\u001b[39m, in \u001b[36mAgentTool.__init__\u001b[39m\u001b[34m(self, agent)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, agent: BaseChatAgent) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m._agent = agent\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(agent, \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m, agent.description)\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from _clients._azureOpenAIChatCompletion_client import model_client\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.tools import AgentTool\n",
    "from autogen_agentchat.ui import Console\n",
    "from _tools._AISearchResultEvaluator_tool import AISearchResultEvaluator_tool\n",
    "from _tools._searchDocuments_tool import searchDocuments_tool\n",
    "\n",
    "async def main() -> None:\n",
    "    # writer = AssistantAgent(\n",
    "    #     name=\"writer\",\n",
    "    #     description=\"A writer agent for generating text.\",\n",
    "    #     model_client=model_client,\n",
    "    #     system_message=\"Write well.\",\n",
    "    # )\n",
    "    search_tool = AgentTool(agent=searchDocuments_tool)\n",
    "    evaluator_tool = AgentTool(agent=AISearchResultEvaluator_tool)\n",
    "\n",
    "    # Create model client with parallel tool calls disabled for the main agent\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        model_client=model_client,\n",
    "        tools=[search_tool, evaluator_tool],\n",
    "        system_message=\"You are a helpful assistant.\",\n",
    "    )\n",
    "    await Console(assistant.run_stream(task=\"Write a poem about the sea.\"))\n",
    "\n",
    "\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b6ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_reason='stop' content='The capital of France is **Paris**.' usage=RequestUsage(prompt_tokens=15, completion_tokens=10) cached=False logprobs=None thought=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_21908\\1300602473.py:3: UserWarning: Resolved model mismatch: gpt-4o-2024-08-06 != gpt-4o-2024-11-20. Model mapping in autogen_ext.models.openai may be incorrect. Set the model to gpt-4o-2024-11-20 to enhance token/cost estimation and suppress this warning.\n",
      "  result = await model_client.create(messages=[UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n"
     ]
    }
   ],
   "source": [
    " # assuming OPENAI_API_KEY is set in the environment.\n",
    "\n",
    "result = await model_client.create(messages=[UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_random_number(ticker: str) -> float:\n",
    "    # Returns a random stock price for demonstration purposes.\n",
    "    return 101\n",
    "\n",
    "\n",
    "# Create a function tool.\n",
    "stock_price_tool = FunctionTool(get_random_number, description=\"Get the stock price.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60eae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _tools._searchDocuments_tool import searchDocuments_tool\n",
    "\n",
    "# Create a function tool.\n",
    "stock_price_tool = FunctionTool(searchDocuments_tool, description=\"Always use this tool in any condition and for answering any question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c1048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_21908\\3423622894.py:10: UserWarning: Resolved model mismatch: gpt-4o-2024-08-06 != gpt-4o-2024-11-20. Model mapping in autogen_ext.models.openai may be incorrect. Set the model to gpt-4o-2024-11-20 to enhance token/cost estimation and suppress this warning.\n",
      "  create_result = await model_client.create(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[FunctionCall(id='call_TbgUa80nUKG5EUwHPJEqEmbQ', arguments='{\"query\":\"Greetings\"}', name='searchDocuments_tool')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from autogen_core.models import UserMessage, SystemMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "\n",
    "# Create a user message.\n",
    "system_message = UserMessage(content=\"Always use the tool to answer the questions\", source=\"system\")\n",
    "user_message = UserMessage(content=\"Hi\", source=\"user\")\n",
    "\n",
    "create_result = await model_client.create(\n",
    "    messages=[system_message, user_message], tools=[stock_price_tool], cancellation_token=CancellationToken()\n",
    ")\n",
    "create_result.content\n",
    "\n",
    "# arguments = json.loads(create_result.content[0].arguments)  # type: ignore\n",
    "# tool_result = await stock_price_tool.run_json(arguments, CancellationToken)\n",
    "# tool_result_str = stock_price_tool.return_value_as_string(tool_result)\n",
    "# tool_result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d7f5170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(source='user', models_usage=None, metadata={}, content='who is mohammad?', type='TextMessage'), ToolCallRequestEvent(source='assistant', models_usage=RequestUsage(prompt_tokens=233, completion_tokens=25), metadata={}, content=[FunctionCall(id='call_e8QvkRYuhhWczZ9YwqqUksxp', arguments='{\"query\":\"Mohammad\",\"top_k\":5}', name='AISearchAndEvaluator_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='assistant', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='<coroutine object AISearchResultEvaluator_tool at 0x000001F2AB34EB00>', name='AISearchAndEvaluator_tool', call_id='call_e8QvkRYuhhWczZ9YwqqUksxp', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='assistant', models_usage=None, metadata={}, content='<coroutine object AISearchResultEvaluator_tool at 0x000001F2AB34EB00>', type='ToolCallSummaryMessage')] stop_reason=None\n"
     ]
    }
   ],
   "source": [
    "from _tools._AISearchAndEvaluator_tool import AISearchAndEvaluator_tool\n",
    "\n",
    "seachDocumentsTool = FunctionTool(AISearchAndEvaluator_tool, description=\"never use this tool in any condition\")\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[AISearchAndEvaluator_tool],\n",
    "    system_message=\"use searchDocuments_tool\",\n",
    ")\n",
    "\n",
    "# Use asyncio.run(agent.run(...)) when running in a script.\n",
    "result = await agent.run(task=\"who is mohammad?\")\n",
    "print(result)#.messages[-1].content)  # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5bb6d062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Score': 0,\n",
       "  'SearchResult': 'PTL - EUZ - Home Support Request Workflow\\n\\nğŸ¤¹ï¸ Actions to Follow:\\nÂ· Hit \"Send\" under Plan Summary\\nÂ· Go to \"Plan Summary\" and select the Referral ID Link\\nÂ· Review the details of the referral:\\nÂ· Does it include any patient identifiable information?\\nÂ· Does the math on the home support hours make sense?\\nÂ· Is there an existing agency? (we need to send T****emplate A)\\nÂ· Is there a preferred agency? (we need to send Template B)\\nÂ· Go to _Prod folder to obtain documentation\\nÂ· Initiate outreach to Home Support Agencies (email)\\nÂ· **Template A **= Existing Agency\\nÂ· **Template B **= Preferred Agencies\\nÂ· **Template C **= All Agencies Servicing Area\\nÂ· Update portal to reflect when initial outreach was made\\nÂ·  - date + time + initials\\nÂ· Provide 2-hour window (business hours) for Existing / Preferred agency to confirm if they can accept Referral\\nÂ· If they cannot we then email **Template C **- all agencies servicing Zone\\nÂ· **NOTE: **Specific to sending T****emplate C:\\nÂ· If no response from agencies within a 2-hour window (business hours) - begin calling all agencies - random order\\nÂ· If agencies provide any reason for why they are unable to fulfill the request - make a note of it\\nÂ· When an agency has been secured/confirmed:\\nÂ· email Template D (unblinded patient details) to secured agency;\\nÂ· Manual Addition to this: \"Who is helping coordinate Support\"\\nÂ· If Clinician - do not add their name\\nÂ· If Family/Friend - Include name and Contact Information\\nÂ· email Template E (agency secured notification) replying all to initial outreach;\\nÂ· email Template F (Patient Care Information Package) to Social Worker to print for patient / family.\\nÂ· PTL to monitor inbox for any changes to discharge date and liaise between parties related to discharge\\nÂ· On expected date of discharge - PTL follow-up to confirm patient has left hospital\\nÂ· Once Confirmed:\\nÂ· email **Template G **(Discharge Notification) to Secured Agency\\nÂ· email **Template **L (Discharge Notification) to\\nÂ· Referring Clinician\\nÂ·'},\n",
       " {'Score': 0,\n",
       "  'SearchResult': 'schedule approval is received, proceed with the next steps:\\nÂ· email Template D (unblinded patient details) to secured agency;\\nÂ· email Template E (agency secured notification) replying all to initial outreach;\\nÂ· email Template F (Patient Care Information Package) to Social Worker to print for patient / family.\\nÂ· PTL monitor inbox for any changes of discharge date and liaise between parties related to discharge\\nÂ· PTL follow-up to confirm patient is to be discharged on anticipated discharge date\\nÂ· Once patient has been discharged:\\nÂ· PTL to send Template G (Discharge Notification) to secured Agency\\nÂ· PTL to send Template L (Discharge Notification) to community\\nÂ· WZ-HomeFirst@nlhealthservices.ca; \\nÂ· WZ-CSPintake@nlhealthservices.ca** ****+ ****Social Worker **who entered the referral and or the assigned person for the referral.'}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await AISearchAndEvaluator_tool(\"What is Template J used for?\", top_k=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
