{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c191a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, base64, asyncio, json, requests\n",
    "from openai import AzureOpenAI\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "# from autogen_ext.teams.magentic_one import MagenticOneGroupChat\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_agentchat.messages import UserMessage\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField, \n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile\n",
    ")\n",
    "# from utility.llm_config import llm_config\n",
    "    \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve credentials from environment variables\n",
    "azure_openAI_api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openAI_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openAI_deployment_name = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "azure_openAI_api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "azure_search_endpoint = os.environ.get(\"AZURE_SEARCH_ENDPOINT\")\n",
    "azure_search_key = os.environ.get(\"AZURE_SEARCH_KEY\")\n",
    "azure_search_deployment_name = os.environ.get(\"AZURE_SEARCH_DEPLOYMENT_NAME\") \n",
    "\n",
    "vector_dimension = 1536  # Dimension for text-embedding-3-small\n",
    "datafile = \"./Data\"\n",
    "azure_search_index_name = \"rag-1756588180789\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58330278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nResult 1:\\nPTL - WZ - Home Support Requests\\n*** Note: No case manager / csp coordinator will be noted in Western – unless the patient already had an agency.\\n🤹️ Actions to Follow:\\n· Hit \"Send\" under Plan Summary\\n· Go to Prod Folder to obtain documentation\\n· Obtain the partially completed EAN form\\n· Update section related to hours in the format of: \" #hours /day, #days /week\"\\n· Update section related to \"Agency/Bookkeeper\" to say \" To be coordinated by DischargeHUB\"\\n· Email the updated EAN form to the referring Social Worker\\n· Once the Social Worker has updated, they will copy dischargeHUB@nlhealthservices.ca on their email to csrequests@nlhealthservices.ca\\n· PTL to send out Template A/B/C - based on requirement of referral\\n· Update portal to reflect when initial outreach was made\\n· \" - date + time + initials\\n· If no response from agencies within a 2-hour window - begin calling - random order \\n· When an agency has been found - two possible scenarios for next steps\\n· Agency found before* *the approval returned:\\n· PTL emails the name of the agency to:  WZ-HomeFirst@nlhealthservices.ca; **csrequests@nlhealthservices.ca **+ cc the referring social worker\\n· Agency found after* *the approval returned:\\n·  PTL emails the name of the agency to: WZ-HomeFirst@nlhealthservices.ca; **csapprovals@nlhealthservices.ca **+ cc the referring social worker\\n· To proceed to the next steps, we do need to confirm that the approval of hours + schedule has happened - this will come via email.\\n· When hours + schedule approval is received, proceed with the next steps:\\n· email Template D (unblinded patient details) to secured agency;\\n· email Template E (agency secured notification) replying all to initial outreach;\\n· email Template F (Patient Care Information Package) to Social Worker to print for patient / family.\\n· PTL monitor inbox for any changes of discharge date and liaise between parties related to discharge\\n· PTL follow-up to confirm patient is to be discharged on anticipated discharge date\\n·\\n\\nResult 2:\\nschedule approval is received, proceed with the next steps:\\n· email Template D (unblinded patient details) to secured agency;\\n· email Template E (agency secured notification) replying all to initial outreach;\\n· email Template F (Patient Care Information Package) to Social Worker to print for patient / family.\\n· PTL monitor inbox for any changes of discharge date and liaise between parties related to discharge\\n· PTL follow-up to confirm patient is to be discharged on anticipated discharge date\\n· Once patient has been discharged:\\n· PTL to send Template G (Discharge Notification) to secured Agency\\n· PTL to send Template L (Discharge Notification) to community\\n· WZ-HomeFirst@nlhealthservices.ca; \\n· WZ-CSPintake@nlhealthservices.ca** ****+ ****Social Worker **who entered the referral and or the assigned person for the referral.\\n\\nResult 3:\\nAyon completed the Strategic Innovation Programme at the Oxford University Saïd Business School. In 2019, he received an Engineering Excellence Award from Queen’s University; and in 2015 he was named one of Atlantic Canada’s Top 50 Under 40.\\n\\nMohammad Sorkhian\\nMohammad Sorkhian is data scientist with a strong background in industrial engineering and computer science. He earned his Master’s degree from Memorial University of Newfoundland and his Bachelor’s degree from Azad University in Iran. Mohammad is skilled in data analysis, including the use of tools like Power BI, as well as web development using technologies like MERN stack, and various programming languages such as Python, JavaScript, and SQL. \\nAs a Developer and Data Analytics Officer at Branch Innovations, Mohammad has led the design and development of numerous tech-forward innovations supporting start-up initiatives and organizations across the Seafair Capital group alike. \\nBefore moving to Canada, Mohammad worked in Iran\\'s automotive and electronics industries, focusing on making software processes more efficient and enhancing production systems. \\nHis academic achievements include research in bioinformatics, where he applied machine learning to biological data. He presented his findings at the CIBB conference, showcasing his ability to apply innovative approaches across different fields. Mohammad has received prestigious awards, including a fellowship at the School of Graduate Studies and a Mitacs award.\\n\\nKelly Perchard\\nKelly is the Portfolio and Projects Coordinator at Branch Innovations. She enables cross-initiative collaboration, supports the development and refinement of new solutions, and facilitates engagement with the broader technology and entrepreneurship communities. \\nKelly previously worked closely with Practicare as Instructional Design Lead.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from _tools._searchDocuments import search_documents\n",
    "\n",
    "search_documents(\"who is Mohammad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4f581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "PTL - WZ - Home Support Requests\n",
      "*** Note: No case manager / csp coordinator will be noted in Western – unless the patient already had an agency.\n",
      "🤹️ Actions to Follow:\n",
      "· Hit \"Send\" under Plan Summary\n",
      "· Go to Prod Folder to obtain documentation\n",
      "· Obtain the partially completed EAN form\n",
      "· Update section related to hours in the format of: \" #hours /day, #days /week\"\n",
      "· Update section related to \"Agency/Bookkeeper\" to say \" To be coordinated by DischargeHUB\"\n",
      "· Email the updated EAN form to the referring Social Worker\n",
      "· Once the Social Worker has updated, they will copy dischargeHUB@nlhealthservices.ca on their email to csrequests@nlhealthservices.ca\n",
      "· PTL to send out Template A/B/C - based on requirement of referral\n",
      "· Update portal to reflect when initial outreach was made\n",
      "· \" - date + time + initials\n",
      "· If no response from agencies within a 2-hour window - begin calling - random order \n",
      "· When an agency has been found - two possible scenarios for next steps\n",
      "· Agency found before* *the approval returned:\n",
      "· PTL emails the name of the agency to:  WZ-HomeFirst@nlhealthservices.ca; **csrequests@nlhealthservices.ca **+ cc the referring social worker\n",
      "· Agency found after* *the approval returned:\n",
      "·  PTL emails the name of the agency to: WZ-HomeFirst@nlhealthservices.ca; **csapprovals@nlhealthservices.ca **+ cc the referring social worker\n",
      "· To proceed to the next steps, we do need to confirm that the approval of hours + schedule has happened - this will come via email.\n",
      "· When hours + schedule approval is received, proceed with the next steps:\n",
      "· email Template D (unblinded patient details) to secured agency;\n",
      "· email Template E (agency secured notification) replying all to initial outreach;\n",
      "· email Template F (Patient Care Information Package) to Social Worker to print for patient / family.\n",
      "· PTL monitor inbox for any changes of discharge date and liaise between parties related to discharge\n",
      "· PTL follow-up to confirm patient is to be discharged on anticipated discharge date\n",
      "·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py:955: UserWarning: Resolved model mismatch: gpt-4o-2024-08-06 != gpt-4o-2024-11-20. Model mapping in autogen_ext.models.openai may be incorrect. Set the model to gpt-4o-2024-11-20 to enhance token/cost estimation and suppress this warning.\n",
      "  model_result = await model_client.create(\n"
     ]
    }
   ],
   "source": [
    "from _clients._azureOpenAIChatCompletion_client import model_client\n",
    "import requests\n",
    "from _clients._openAI_client import openAI_client\n",
    "\n",
    "\n",
    "\n",
    "def embed_text(text):\n",
    "    response = openAI_client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=azure_search_deployment_name\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    return embedding\n",
    "\n",
    "\n",
    "\n",
    "def search_documents(query=[], top_k=3):\n",
    "\n",
    "    embedding = embed_text(query)\n",
    "\n",
    "    url= f\"{azure_search_endpoint}/indexes/{azure_search_index_name}/docs/search?api-version={'2023-07-01-Preview'}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": azure_search_key\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"count\": True,\n",
    "        \"search\":\"{query}\",\n",
    "        \"vector\": {\n",
    "            \"value\": embedding,\n",
    "            \"k\": top_k,\n",
    "            \"fields\": \"text_vector\"\n",
    "        },\n",
    "        \"top\": top_k\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    response = response.json().get(\"value\", [])\n",
    "    response = [doc.get(\"chunk\") for doc in response if doc.get(\"chunk\")]\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "userQuery = \"waht is template J for?\"\n",
    "\n",
    "result = search_documents(userQuery)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _clients._azureOpenAIChatCompletion_client import model_client\n",
    "import os, requests\n",
    "import requests\n",
    "from _clients._openAI_client import openAI_client\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "# Define Pydantic model for a single integer output\n",
    "class Output_ragResultEvaluator(BaseModel):\n",
    "    value: int = Field(..., ge=0, le=100)  # Integer from 0 to 100\n",
    "\n",
    "\n",
    "\n",
    "def embed_text(text):\n",
    "    response = openAI_client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=azure_search_deployment_name\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    return embedding\n",
    "\n",
    "\n",
    "\n",
    "def search_documents(query=[], top_k=3):\n",
    "\n",
    "    embedding = embed_text(query)\n",
    "\n",
    "    url= f\"{azure_search_endpoint}/indexes/{azure_search_index_name}/docs/search?api-version={'2023-07-01-Preview'}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": azure_search_key\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"count\": True,\n",
    "        \"search\":\"{query}\",\n",
    "        \"vector\": {\n",
    "            \"value\": embedding,\n",
    "            \"k\": top_k,\n",
    "            \"fields\": \"text_vector\"\n",
    "        },\n",
    "        \"top\": top_k\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    response = response.json().get(\"value\", [])\n",
    "    response = [doc.get(\"chunk\") for doc in response if doc.get(\"chunk\")]\n",
    "\n",
    "    return response\n",
    "\n",
    "result = search_documents(\"who is Mohammad?\")\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"RetrievedResultEvaluator\",\n",
    "    model_client= model_client,\n",
    "    system_message=\"You are a helpful assistant. that get a user 'query' and a 'result'. I want you to compare the user query with the result and if the result helps to answer the user query, return an core between o to 100. 0 shows the least relevancy between query and result while 100 shows the mosts'\",\n",
    "    output_content_type=Output_ragResultEvaluator\n",
    ")\n",
    "\n",
    "result = result[2]\n",
    "\n",
    "result_ev = await agent.run(task=f\"query: who is Mohammad? result: {result}\")\n",
    "print(result_ev.messages[-1].content)  # Outputs the final summarized response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5287d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Assistant Agent\n",
    "# assistant_bestFormatFinder  = AssistantAgent(\n",
    "#     name='formatFinder', \n",
    "#     model_client=model_client,\n",
    "#     system_message=\"you always say i donot know\",\n",
    "#     )\n",
    "\n",
    "# assistant_findAnswer  = AssistantAgent(\n",
    "#     name='answerFinder', \n",
    "#     model_client=model_client,\n",
    "#     system_message=\"You find the answer to the user's question based on the provided context, tools and knowledge you have\",\n",
    "#     )\n",
    "\n",
    "# assistant_evaliation = AssistantAgent(\n",
    "#     name='evaluator', \n",
    "#     model_client=model_client,\n",
    "#     system_message=\"You evaluate the final output based on the user's query, provided context and tools and your knowledge\",\n",
    "#     )   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92d6ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result= await assistant_evaliation.run(task=\"where is paris? answer in one word\")\n",
    "# print(result.messages[-1].content) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1d26e",
   "metadata": {},
   "source": [
    "### Udemy Course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6208a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from _clients._azureOpenAIChatCompletion_client import AzureOpenAIChatCompletionClient\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
